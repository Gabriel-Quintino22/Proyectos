# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lKcW5PXG7fW_pvoG2WgAejkAebCdJc5R
"""

import pandas as pd  #Importe de librerias como pd,np,matplot
                      #Seaborn, sm, y coloco en el codigo
                      #la base de datos.
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from scipy.stats import f_oneway
import statsmodels.api as sm
from statsmodels.formula.api import ols

df = pd.read_excel('/content/datos_evsum3.xlsx')

df.head()    #Vemos la base de datos para darle una repasada

import pandas as pd

df = pd.read_excel('/content/datos_evsum3.xlsx')
print("DataFrame 'df' loaded successfully.")

df.columns   #Aca vemos columns para ver las variables
             #que contiene la base de datos

df.info   #Y aca por sis tiene algun info adicional

#Este codigo lo hago precisamente para la recodificacion de
#la variable, "estudiante"compra_premium"tipo_cliente"

for col in ['estudiante', 'compra_premium', 'tipo_cliente']:
    print("\n", col)
    print(df[col].astype(str).str.strip().value_counts(dropna=False))

#Este codigo asigna en codigo binario: si/no


map_bin = {'No': 0, 'Si': 1}

df['estudiante_num'] = df['estudiante'].map(map_bin)
df['compra_premium_num'] = df['compra_premium'].map(map_bin)

df[['estudiante','estudiante_num','compra_premium','compra_premium_num']].head()

#El print principalmente es para ver los resultados

print(df['estudiante_num'].value_counts())
print(df['compra_premium_num'].value_counts())

#Analisis de ANOVA, entre los estudiantes(1)
#y los no estudiantes(0)

from scipy.stats import f_oneway

g0 = df.loc[df['estudiante_num'] == 0, 'sat_compra']
g1 = df.loc[df['estudiante_num'] == 1, 'sat_compra']

f_stat, p_val = f_oneway(g0, g1)
print(f"ANOVA sat_compra ~ estudiante | F={f_stat:.3f} | p={p_val:.4f} | n0={len(g0)} n1={len(g1)}")

#En el grafico la unica diferencia que se puede ver
#es que los No estudiantes tienen una mediana de satisfacccion
#de compra por un indicador mas que los qu si estudian

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(7,5))
sns.boxplot(x='estudiante', y='sat_compra', data=df)
plt.title('Satisfacción de compra por condición de estudiante')
plt.show()

import statsmodels.api as sm
from statsmodels.formula.api import ols

model = ols('sat_compra ~ C(tipo_cliente)', data=df).fit()
anova_table = sm.stats.anova_lm(model, typ=2)
anova_table

#La satisfaccion de compra se puede ver en el eje Y.
#y se puede ver en el eje x los distintos grupos
#tales como cliente leal, que su 50% de satisfaccion de compra
#esta entre 2 y 4, su mediana es de 3 y el primer cuartil,
#comiennza desde el 1 y termina en el 2, cuando comienza
#la caja.

plt.figure(figsize=(9,5))
sns.boxplot(x='tipo_cliente', y='sat_compra', data=df)
plt.title('Satisfacción de compra por tipo de cliente')
plt.xticks(rotation=20, ha='right')
plt.show()

from statsmodels.stats.multicomp import pairwise_tukeyhsd

tukey = pairwise_tukeyhsd(endog=df['sat_compra'], groups=df['tipo_cliente'], alpha=0.05)
print(tukey)

import statsmodels.api as sm
from statsmodels.formula.api import ols

# Asegurar que compra_premium sea categórica (no numérica) para ANOVA
df['compra_premium'] = df['compra_premium'].astype('category')
df['tipo_cliente'] = df['tipo_cliente'].astype('category')

model_2way = ols('sat_compra ~ C(tipo_cliente) * C(compra_premium)', data=df).fit()
anova_2way = sm.stats.anova_lm(model_2way, typ=2)
anova_2way

plt.figure(figsize=(8,5))
sns.pointplot(data=df, x='tipo_cliente', y='sat_compra', hue='compra_premium',
              errorbar=('ci', 95), dodge=True)
plt.xticks(rotation=20, ha='right')
plt.title('Satisfacción por tipo de cliente y compra premium (medias + IC95%)')
plt.show()

m_simple = ols('sat_compra ~ tiempo_web', data=df).fit()
print(m_simple.summary())

m_simple = ols('sat_compra ~ tiempo_web', data=df).fit()
print(m_simple.summary())

#Se puede apreciar que con la variable que suma en esta
#regresion multiple 'cal_facuso', aumenta el r2, por ende
#aumenta la variabilidad del modelo fuertemente con la inclusion
#de esta variable en el modelo ols.

m_multi = ols('sat_compra ~ cal_facuso + cal_respuesta', data=df).fit()
print(m_multi.summary())

from statsmodels.stats.outliers_influence import variance_inflation_factor

X = df[['cal_facuso', 'cal_respuesta']].copy()
X = sm.add_constant(X)

vif = pd.DataFrame({
    'feature': X.columns,
    'VIF': [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
})
vif

df['tiempo_pedido2'] = df['tiempo_pedido']**2

m_quad = ols('sat_compra ~ tiempo_pedido + tiempo_pedido2', data=df).fit()
print(m_quad.summary())

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer

from sklearn.linear_model import LinearRegression, Ridge
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

target = 'sat_compra'

features_num = [
    'tiempo_web', 'cal_facuso', 'cal_respuesta', 'cal_disenio',
    'cal_fiabilidad', 'cal_variedad', 'tiempo_pedido', 'frec_visita'
]

features_cat = ['tipo_cliente', 'tipo_empleo', 'estudiante', 'compra_premium']

X = df[features_num + features_cat]
y = df[target]

numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median"))
])

categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(drop="first", handle_unknown="ignore"))
])

preprocess = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, features_num),
        ("cat", categorical_transformer, features_cat)
    ]
)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=123
)

modelos = {
    "Regresión Lineal": LinearRegression(),
    "Ridge": Ridge(alpha=1.0, random_state=123),
    "Árbol de Decisión": DecisionTreeRegressor(random_state=123),
    "Random Forest": RandomForestRegressor(random_state=123, n_estimators=300),
    "KNN": KNeighborsRegressor()
}

resultados = []

for nombre, modelo in modelos.items():
    pipe = Pipeline(steps=[
        ("preprocess", preprocess),
        ("model", modelo)
    ])

    pipe.fit(X_train, y_train)
    pred = pipe.predict(X_test)

    r2 = r2_score(y_test, pred)
    mae = mean_absolute_error(y_test, pred)
    rmse = np.sqrt(mean_squared_error(y_test, pred))

    resultados.append({
        "Modelo": nombre,
        "R2": r2,
        "MAE": mae,
        "RMSE": rmse
    })

df_resultados = pd.DataFrame(resultados).sort_values(by="RMSE")
df_resultados

best_model_name = "Random Forest"

pipe_best = Pipeline(steps=[
    ("preprocess", preprocess),
    ("model", modelos[best_model_name])
])

pipe_best.fit(X_train, y_train)

# nombres de columnas post one-hot
ohe = pipe_best.named_steps["preprocess"].named_transformers_["cat"].named_steps["onehot"]
cat_feature_names = ohe.get_feature_names_out(features_cat)

all_feature_names = np.concatenate([features_num, cat_feature_names])

importances = pipe_best.named_steps["model"].feature_importances_
imp = pd.DataFrame({"feature": all_feature_names, "importance": importances}).sort_values("importance", ascending=False)

imp.head(15)